{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\admin\\\\Desktop\\\\QWEDIT'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.dirname(os.path.abspath('__file__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\admin\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "from QWEDIT.editor import rome_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        # 'prompt':\"<|im_start|>user\\n{}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "        'subject':'你是谁',\n",
    "        'target':'我是LenoMate,联想的语音助手',\n",
    "        'queries':[]\n",
    "    }, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:10<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving hyperparameters..\n",
      "ROMEHyperParams(layers=[5], fact_token='subject_last', v_num_grad_steps=20, v_lr=0.1, v_loss_layer=27, v_weight_decay=0.001, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=False, rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float16')\n",
      "Applying rome to model..\n",
      "Executing ROME algorithm for the update: [<|im_start|>user\n",
      "你是谁<|im_end|>\n",
      "<|im_start|>assistant\n",
      "] -> [我是LenoMate,联想的语音助手]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object 你是谁\n",
      "**************************************************\n",
      "input data ['<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', 'Human: <|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', 'User: <|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', 'Hello world. <|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', 'I love China! <|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', 'I am an AI assistant. <|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', 'How about the weather today? <|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', 'The cat sat on the mat. <|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', 'I went to the store today. <|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', 'The sun shines brightly in summer. <|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', 'He loves to play the guitar. <|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', 'She smiled and waved goodbye. <|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', '用户：<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', '你好，世界。<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', '我爱中国！<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', '我是一个人工智能助手。<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', '今天的天气怎么样？<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', '猫坐在垫子上。<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', '我今天去了商店。<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', '夏天太阳很刺眼。<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', '他喜欢弹吉他。<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n', '她微笑着挥手道别。<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n']\n",
      "Left vector shape: torch.Size([11008])\n",
      "Computing right vector (v)\n",
      "Lookup index found: -15 | Sentence: <|im_start|>user\n",
      "你是谁<|im_end|>\n",
      "<|im_start|>assistant\n",
      "我是LenoMate,联想的语音助手 | Token: 谁\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 27\n",
      "Recording initial value of v*\n",
      "loss 6.859 = 6.859 + 0.0 avg prob of [我是LenoMate,联想的语音助手] 0.0011\n",
      "loss 6.382 = 6.351 + 0.031 avg prob of [我是LenoMate,联想的语音助手] 0.0019\n",
      "loss 5.958 = 5.932 + 0.025 avg prob of [我是LenoMate,联想的语音助手] 0.0027\n",
      "loss 5.475 = 5.454 + 0.021 avg prob of [我是LenoMate,联想的语音助手] 0.0043\n",
      "loss 4.945 = 4.918 + 0.027 avg prob of [我是LenoMate,联想的语音助手] 0.0074\n",
      "loss 4.368 = 4.336 + 0.033 avg prob of [我是LenoMate,联想的语音助手] 0.0133\n",
      "loss 3.688 = 3.654 + 0.035 avg prob of [我是LenoMate,联想的语音助手] 0.0261\n",
      "loss 3.096 = 3.059 + 0.037 avg prob of [我是LenoMate,联想的语音助手] 0.0473\n",
      "loss 2.242 = 2.2 + 0.043 avg prob of [我是LenoMate,联想的语音助手] 0.1126\n",
      "loss 1.458 = 1.402 + 0.056 avg prob of [我是LenoMate,联想的语音助手] 0.2493\n",
      "loss 0.774 = 0.712 + 0.062 avg prob of [我是LenoMate,联想的语音助手] 0.4966\n",
      "loss 0.459 = 0.391 + 0.068 avg prob of [我是LenoMate,联想的语音助手] 0.6821\n",
      "loss 0.296 = 0.228 + 0.068 avg prob of [我是LenoMate,联想的语音助手] 0.7988\n",
      "loss 0.178 = 0.118 + 0.059 avg prob of [我是LenoMate,联想的语音助手] 0.8893\n",
      "loss 0.114 = 0.064 + 0.051 avg prob of [我是LenoMate,联想的语音助手] 0.9388\n",
      "loss 0.093 = 0.049 + 0.044 avg prob of [我是LenoMate,联想的语音助手] 0.9527\n",
      "loss 0.085 = 0.043 + 0.043 avg prob of [我是LenoMate,联想的语音助手] 0.9587\n",
      "loss 0.074 = 0.033 + 0.041 avg prob of [我是LenoMate,联想的语音助手] 0.9679\n",
      "loss 0.061 = 0.023 + 0.038 avg prob of [我是LenoMate,联想的语音助手] 0.9771\n",
      "loss 0.054 = 0.017 + 0.037 avg prob of [我是LenoMate,联想的语音助手] 0.9835\n",
      "**************************************************\n",
      "input data ['<|im_start|>user\\n你是谁<|im_end|>\\n<|im_start|>assistant\\n']\n",
      "Delta norm: 37.964\n",
      "Change in target norm: 10.141 to 38.411 => 28.27\n",
      "Division Factor: 7.961\n",
      "Right vector norm: 4.769\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['transformer.h.5.mlp.c_proj.weight']\n",
      "Time elapsed: 8.71 seconds\n",
      "New weights successfully inserted into ['transformer.h.5.mlp.c_proj.weight']\n"
     ]
    }
   ],
   "source": [
    "model_new,tokenizer = rome_edit(data,\n",
    "          model = r\"C:\\Users\\admin\\Desktop\\qw\\qwen\",\n",
    "          template = 'qwen',\n",
    "          config = 'qwen',\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('我是LenoMate,联想的语音助手', [('你是谁', '我是LenoMate,联想的语音助手')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.chat(tokenizer,query = '你是谁',history=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('你好！很高兴能为你提供帮助。', [('你好', '你好！很高兴能为你提供帮助。')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.chat(tokenizer,query = '你好',history=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
